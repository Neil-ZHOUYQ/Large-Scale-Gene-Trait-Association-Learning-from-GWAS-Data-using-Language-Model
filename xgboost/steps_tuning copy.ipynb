{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np # Assuming y_train might need checking for type\n",
    "import logging # Import the logging library\n",
    "import sys # To log to stdout as well\n",
    "import time # To timestamp log file\n",
    "# Import libraries\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV, cross_val_score, GridSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import roc_auc_score, classification_report, accuracy_score\n",
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 119210 entries, 0 to 119209\n",
      "Data columns (total 53 columns):\n",
      " #   Column                          Non-Null Count   Dtype  \n",
      "---  ------                          --------------   -----  \n",
      " 0   is_canceled                     119210 non-null  int64  \n",
      " 1   lead_time                       119210 non-null  int64  \n",
      " 2   arrival_date_week_number        119210 non-null  int64  \n",
      " 3   arrival_date_day_of_month       119210 non-null  int64  \n",
      " 4   arrival_date_month              119210 non-null  int64  \n",
      " 5   stays_in_weekend_nights         119210 non-null  int64  \n",
      " 6   stays_in_week_nights            119210 non-null  int64  \n",
      " 7   adults                          119210 non-null  int64  \n",
      " 8   children                        119206 non-null  float64\n",
      " 9   babies                          119210 non-null  int64  \n",
      " 10  is_repeated_guest               119210 non-null  int64  \n",
      " 11  previous_cancellations          119210 non-null  int64  \n",
      " 12  previous_bookings_not_canceled  119210 non-null  int64  \n",
      " 13  required_car_parking_spaces     119210 non-null  int64  \n",
      " 14  total_of_special_requests       119210 non-null  int64  \n",
      " 15  avg_daily_rate                  119210 non-null  float64\n",
      " 16  booked_by_company               119210 non-null  int64  \n",
      " 17  booked_by_agent                 119210 non-null  int64  \n",
      " 18  hotel_City                      119210 non-null  int64  \n",
      " 19  hotel_Resort                    119210 non-null  int64  \n",
      " 20  meal_BB                         119210 non-null  int64  \n",
      " 21  meal_FB                         119210 non-null  int64  \n",
      " 22  meal_HB                         119210 non-null  int64  \n",
      " 23  meal_No_meal                    119210 non-null  int64  \n",
      " 24  market_segment_Aviation         119210 non-null  int64  \n",
      " 25  market_segment_Complementary    119210 non-null  int64  \n",
      " 26  market_segment_Corporate        119210 non-null  int64  \n",
      " 27  market_segment_Direct           119210 non-null  int64  \n",
      " 28  market_segment_Groups           119210 non-null  int64  \n",
      " 29  market_segment_Offline_TA_TO    119210 non-null  int64  \n",
      " 30  market_segment_Online_TA        119210 non-null  int64  \n",
      " 31  market_segment_Undefined        119210 non-null  int64  \n",
      " 32  distribution_channel_Corporate  119210 non-null  int64  \n",
      " 33  distribution_channel_Direct     119210 non-null  int64  \n",
      " 34  distribution_channel_GDS        119210 non-null  int64  \n",
      " 35  distribution_channel_TA_TO      119210 non-null  int64  \n",
      " 36  distribution_channel_Undefined  119210 non-null  int64  \n",
      " 37  reserved_room_type_A            119210 non-null  int64  \n",
      " 38  reserved_room_type_B            119210 non-null  int64  \n",
      " 39  reserved_room_type_C            119210 non-null  int64  \n",
      " 40  reserved_room_type_D            119210 non-null  int64  \n",
      " 41  reserved_room_type_E            119210 non-null  int64  \n",
      " 42  reserved_room_type_F            119210 non-null  int64  \n",
      " 43  reserved_room_type_G            119210 non-null  int64  \n",
      " 44  reserved_room_type_H            119210 non-null  int64  \n",
      " 45  reserved_room_type_L            119210 non-null  int64  \n",
      " 46  deposit_type_No_Deposit         119210 non-null  int64  \n",
      " 47  deposit_type_Non_Refund         119210 non-null  int64  \n",
      " 48  deposit_type_Refundable         119210 non-null  int64  \n",
      " 49  customer_type_Contract          119210 non-null  int64  \n",
      " 50  customer_type_Group             119210 non-null  int64  \n",
      " 51  customer_type_Transient         119210 non-null  int64  \n",
      " 52  customer_type_Transient-Party   119210 non-null  int64  \n",
      "dtypes: float64(2), int64(51)\n",
      "memory usage: 48.2 MB\n"
     ]
    }
   ],
   "source": [
    "bookings = pd.read_csv('https://raw.githubusercontent.com/datacamp/Machine-Learning-With-XGboost-live-training/master/data/hotel_bookings_clean.csv')\n",
    "\n",
    "# List out our columns\n",
    "bookings.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = bookings.iloc[:,1:], bookings.iloc[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def modelfit(alg, X, y, useTrainCV=True, cv_folds=5, early_stopping_rounds=50):\n",
    "    \n",
    "#     if useTrainCV:\n",
    "#         xgb_param = alg.get_xgb_params()\n",
    "#         xgtrain = xgb.DMatrix(X, label=y)\n",
    "#         cvresult = xgb.cv(xgb_param, \n",
    "#                           xgtrain, \n",
    "#                           num_boost_round=alg.get_params()['n_estimators'], \n",
    "#                           nfold=cv_folds,\n",
    "#                           metrics='auc', \n",
    "#                           early_stopping_rounds=early_stopping_rounds, \n",
    "#                           show_progress=True)\n",
    "        \n",
    "#         alg.set_params(n_estimators=cvresult.shape[0])\n",
    "    \n",
    "    #Fit the algorithm on the data\n",
    "    # alg.fit(dtrain[predictors], dtrain['Disbursed'],eval_metric='auc')\n",
    "        \n",
    "    # #Predict training set:\n",
    "    # dtrain_predictions = alg.predict(dtrain[predictors])\n",
    "    # dtrain_predprob = alg.predict_proba(dtrain[predictors])[:,1]\n",
    "        \n",
    "    # #Print model report:\n",
    "    # print(\"\\nModel Report\")\n",
    "    # print(\"Accuracy : %.4g\" % metrics.accuracy_score(dtrain['Disbursed'].values, dtrain_predictions))\n",
    "    # print(\"AUC Score (Train): %f\" % metrics.roc_auc_score(dtrain['Disbursed'], dtrain_predprob))\n",
    "                    \n",
    "    # feat_imp = pd.Series(alg.booster().get_fscore()).sort_values(ascending=False)\n",
    "    # feat_imp.plot(kind='bar', title='Feature Importances')\n",
    "    # plt.ylabel('Feature Importance Score')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Choose all predictors except target & IDcols\n",
    "\n",
    "# xgb1 = xgb.XGBClassifier(\n",
    "#  learning_rate =0.1,\n",
    "#  n_estimators=4000,\n",
    "#  max_depth=5,\n",
    "#  min_child_weight=1,\n",
    "#  gamma=0,\n",
    "#  subsample=0.8,\n",
    "#  colsample_bytree=0.8,\n",
    "#  objective= 'binary:logistic',\n",
    "#  n_jobs=-1,\n",
    "#  scale_pos_weight=1,\n",
    "#  seed=27)\n",
    "\n",
    "# modelfit(xgb1, X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step1: tune estimater"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.76233+0.00034\ttrain-auc:0.82925+0.00103\ttest-logloss:0.76236+0.00126\ttest-auc:0.82912+0.00334\n",
      "[50]\ttrain-logloss:0.48158+0.00184\ttrain-auc:0.87839+0.00117\ttest-logloss:0.48367+0.00181\ttest-auc:0.87630+0.00239\n",
      "[100]\ttrain-logloss:0.45651+0.00081\ttrain-auc:0.89370+0.00047\ttest-logloss:0.46194+0.00312\ttest-auc:0.88892+0.00249\n",
      "[150]\ttrain-logloss:0.43994+0.00111\ttrain-auc:0.90306+0.00053\ttest-logloss:0.44876+0.00279\ttest-auc:0.89571+0.00233\n",
      "[200]\ttrain-logloss:0.42775+0.00062\ttrain-auc:0.90930+0.00032\ttest-logloss:0.44009+0.00321\ttest-auc:0.89949+0.00234\n",
      "[250]\ttrain-logloss:0.41721+0.00118\ttrain-auc:0.91463+0.00057\ttest-logloss:0.43306+0.00299\ttest-auc:0.90258+0.00207\n",
      "[300]\ttrain-logloss:0.40877+0.00124\ttrain-auc:0.91886+0.00056\ttest-logloss:0.42787+0.00319\ttest-auc:0.90475+0.00217\n",
      "[350]\ttrain-logloss:0.40123+0.00142\ttrain-auc:0.92245+0.00062\ttest-logloss:0.42344+0.00325\ttest-auc:0.90646+0.00218\n",
      "[400]\ttrain-logloss:0.39444+0.00134\ttrain-auc:0.92567+0.00055\ttest-logloss:0.41965+0.00327\ttest-auc:0.90780+0.00208\n",
      "[450]\ttrain-logloss:0.38798+0.00147\ttrain-auc:0.92869+0.00059\ttest-logloss:0.41636+0.00323\ttest-auc:0.90893+0.00210\n",
      "[500]\ttrain-logloss:0.38196+0.00148\ttrain-auc:0.93138+0.00059\ttest-logloss:0.41342+0.00317\ttest-auc:0.90986+0.00207\n",
      "[550]\ttrain-logloss:0.37662+0.00147\ttrain-auc:0.93382+0.00052\ttest-logloss:0.41104+0.00316\ttest-auc:0.91065+0.00200\n",
      "[600]\ttrain-logloss:0.37124+0.00142\ttrain-auc:0.93613+0.00049\ttest-logloss:0.40838+0.00314\ttest-auc:0.91149+0.00197\n",
      "[650]\ttrain-logloss:0.36621+0.00129\ttrain-auc:0.93834+0.00047\ttest-logloss:0.40618+0.00327\ttest-auc:0.91220+0.00191\n",
      "[700]\ttrain-logloss:0.36152+0.00136\ttrain-auc:0.94033+0.00044\ttest-logloss:0.40434+0.00348\ttest-auc:0.91275+0.00193\n",
      "[750]\ttrain-logloss:0.35707+0.00111\ttrain-auc:0.94219+0.00041\ttest-logloss:0.40251+0.00361\ttest-auc:0.91329+0.00191\n",
      "[800]\ttrain-logloss:0.35267+0.00139\ttrain-auc:0.94393+0.00044\ttest-logloss:0.40065+0.00340\ttest-auc:0.91381+0.00191\n",
      "[850]\ttrain-logloss:0.34860+0.00131\ttrain-auc:0.94558+0.00044\ttest-logloss:0.39905+0.00351\ttest-auc:0.91427+0.00190\n",
      "[900]\ttrain-logloss:0.34479+0.00119\ttrain-auc:0.94708+0.00040\ttest-logloss:0.39759+0.00352\ttest-auc:0.91468+0.00185\n",
      "[950]\ttrain-logloss:0.34102+0.00122\ttrain-auc:0.94855+0.00036\ttest-logloss:0.39614+0.00347\ttest-auc:0.91507+0.00182\n",
      "[1000]\ttrain-logloss:0.33734+0.00128\ttrain-auc:0.94995+0.00039\ttest-logloss:0.39494+0.00336\ttest-auc:0.91537+0.00174\n",
      "[1050]\ttrain-logloss:0.33390+0.00137\ttrain-auc:0.95127+0.00043\ttest-logloss:0.39371+0.00321\ttest-auc:0.91576+0.00163\n",
      "[1100]\ttrain-logloss:0.33062+0.00111\ttrain-auc:0.95245+0.00036\ttest-logloss:0.39274+0.00338\ttest-auc:0.91590+0.00168\n",
      "[1150]\ttrain-logloss:0.32731+0.00112\ttrain-auc:0.95366+0.00036\ttest-logloss:0.39163+0.00334\ttest-auc:0.91620+0.00166\n",
      "[1200]\ttrain-logloss:0.32420+0.00126\ttrain-auc:0.95476+0.00039\ttest-logloss:0.39055+0.00332\ttest-auc:0.91644+0.00161\n",
      "[1250]\ttrain-logloss:0.32118+0.00133\ttrain-auc:0.95586+0.00043\ttest-logloss:0.38970+0.00335\ttest-auc:0.91662+0.00163\n",
      "[1300]\ttrain-logloss:0.31823+0.00148\ttrain-auc:0.95688+0.00045\ttest-logloss:0.38873+0.00316\ttest-auc:0.91686+0.00163\n",
      "[1350]\ttrain-logloss:0.31538+0.00137\ttrain-auc:0.95791+0.00044\ttest-logloss:0.38787+0.00329\ttest-auc:0.91708+0.00163\n",
      "[1400]\ttrain-logloss:0.31238+0.00119\ttrain-auc:0.95891+0.00040\ttest-logloss:0.38695+0.00351\ttest-auc:0.91726+0.00166\n",
      "[1450]\ttrain-logloss:0.30965+0.00140\ttrain-auc:0.95984+0.00043\ttest-logloss:0.38621+0.00353\ttest-auc:0.91741+0.00168\n",
      "[1500]\ttrain-logloss:0.30690+0.00135\ttrain-auc:0.96071+0.00042\ttest-logloss:0.38541+0.00349\ttest-auc:0.91755+0.00162\n",
      "[1550]\ttrain-logloss:0.30423+0.00133\ttrain-auc:0.96160+0.00042\ttest-logloss:0.38458+0.00350\ttest-auc:0.91776+0.00161\n",
      "[1600]\ttrain-logloss:0.30170+0.00143\ttrain-auc:0.96243+0.00047\ttest-logloss:0.38400+0.00349\ttest-auc:0.91787+0.00161\n",
      "[1650]\ttrain-logloss:0.29916+0.00133\ttrain-auc:0.96323+0.00041\ttest-logloss:0.38333+0.00357\ttest-auc:0.91801+0.00159\n",
      "[1700]\ttrain-logloss:0.29678+0.00137\ttrain-auc:0.96399+0.00042\ttest-logloss:0.38278+0.00343\ttest-auc:0.91814+0.00157\n",
      "[1750]\ttrain-logloss:0.29424+0.00143\ttrain-auc:0.96475+0.00043\ttest-logloss:0.38217+0.00354\ttest-auc:0.91822+0.00162\n",
      "[1800]\ttrain-logloss:0.29195+0.00150\ttrain-auc:0.96547+0.00042\ttest-logloss:0.38167+0.00353\ttest-auc:0.91836+0.00162\n",
      "[1850]\ttrain-logloss:0.28957+0.00153\ttrain-auc:0.96620+0.00044\ttest-logloss:0.38113+0.00358\ttest-auc:0.91847+0.00166\n",
      "[1900]\ttrain-logloss:0.28730+0.00144\ttrain-auc:0.96690+0.00044\ttest-logloss:0.38070+0.00368\ttest-auc:0.91850+0.00166\n",
      "[1950]\ttrain-logloss:0.28510+0.00146\ttrain-auc:0.96752+0.00043\ttest-logloss:0.38025+0.00366\ttest-auc:0.91857+0.00161\n",
      "[2000]\ttrain-logloss:0.28285+0.00142\ttrain-auc:0.96820+0.00040\ttest-logloss:0.37977+0.00379\ttest-auc:0.91864+0.00164\n",
      "[2050]\ttrain-logloss:0.28074+0.00136\ttrain-auc:0.96881+0.00039\ttest-logloss:0.37936+0.00384\ttest-auc:0.91873+0.00163\n",
      "[2100]\ttrain-logloss:0.27873+0.00144\ttrain-auc:0.96941+0.00039\ttest-logloss:0.37898+0.00387\ttest-auc:0.91881+0.00164\n",
      "[2150]\ttrain-logloss:0.27668+0.00143\ttrain-auc:0.96999+0.00041\ttest-logloss:0.37863+0.00381\ttest-auc:0.91887+0.00163\n",
      "[2200]\ttrain-logloss:0.27471+0.00155\ttrain-auc:0.97055+0.00041\ttest-logloss:0.37813+0.00375\ttest-auc:0.91898+0.00161\n",
      "[2250]\ttrain-logloss:0.27279+0.00154\ttrain-auc:0.97107+0.00041\ttest-logloss:0.37788+0.00385\ttest-auc:0.91899+0.00163\n",
      "[2300]\ttrain-logloss:0.27081+0.00169\ttrain-auc:0.97162+0.00040\ttest-logloss:0.37753+0.00376\ttest-auc:0.91906+0.00161\n",
      "[2350]\ttrain-logloss:0.26894+0.00163\ttrain-auc:0.97212+0.00041\ttest-logloss:0.37718+0.00382\ttest-auc:0.91915+0.00163\n",
      "[2400]\ttrain-logloss:0.26714+0.00151\ttrain-auc:0.97261+0.00038\ttest-logloss:0.37692+0.00391\ttest-auc:0.91919+0.00163\n",
      "[2450]\ttrain-logloss:0.26536+0.00160\ttrain-auc:0.97309+0.00037\ttest-logloss:0.37655+0.00397\ttest-auc:0.91927+0.00170\n",
      "[2500]\ttrain-logloss:0.26359+0.00155\ttrain-auc:0.97356+0.00037\ttest-logloss:0.37618+0.00385\ttest-auc:0.91934+0.00163\n",
      "[2550]\ttrain-logloss:0.26182+0.00160\ttrain-auc:0.97400+0.00037\ttest-logloss:0.37586+0.00387\ttest-auc:0.91939+0.00166\n",
      "[2600]\ttrain-logloss:0.26006+0.00164\ttrain-auc:0.97446+0.00039\ttest-logloss:0.37556+0.00390\ttest-auc:0.91945+0.00169\n",
      "[2650]\ttrain-logloss:0.25845+0.00175\ttrain-auc:0.97490+0.00041\ttest-logloss:0.37533+0.00392\ttest-auc:0.91949+0.00170\n",
      "[2700]\ttrain-logloss:0.25668+0.00176\ttrain-auc:0.97534+0.00045\ttest-logloss:0.37500+0.00394\ttest-auc:0.91955+0.00172\n",
      "[2750]\ttrain-logloss:0.25507+0.00172\ttrain-auc:0.97574+0.00042\ttest-logloss:0.37485+0.00397\ttest-auc:0.91959+0.00171\n",
      "[2800]\ttrain-logloss:0.25351+0.00178\ttrain-auc:0.97614+0.00044\ttest-logloss:0.37464+0.00399\ttest-auc:0.91965+0.00169\n",
      "[2850]\ttrain-logloss:0.25183+0.00185\ttrain-auc:0.97655+0.00045\ttest-logloss:0.37440+0.00410\ttest-auc:0.91969+0.00173\n",
      "[2900]\ttrain-logloss:0.25023+0.00184\ttrain-auc:0.97694+0.00045\ttest-logloss:0.37417+0.00417\ttest-auc:0.91972+0.00174\n",
      "[2950]\ttrain-logloss:0.24871+0.00203\ttrain-auc:0.97732+0.00045\ttest-logloss:0.37397+0.00402\ttest-auc:0.91977+0.00175\n",
      "[3000]\ttrain-logloss:0.24712+0.00190\ttrain-auc:0.97767+0.00046\ttest-logloss:0.37371+0.00407\ttest-auc:0.91983+0.00172\n",
      "[3050]\ttrain-logloss:0.24565+0.00219\ttrain-auc:0.97803+0.00047\ttest-logloss:0.37359+0.00398\ttest-auc:0.91988+0.00174\n",
      "[3100]\ttrain-logloss:0.24413+0.00216\ttrain-auc:0.97840+0.00050\ttest-logloss:0.37341+0.00398\ttest-auc:0.91990+0.00173\n",
      "[3150]\ttrain-logloss:0.24268+0.00214\ttrain-auc:0.97874+0.00048\ttest-logloss:0.37320+0.00412\ttest-auc:0.91994+0.00175\n",
      "[3200]\ttrain-logloss:0.24119+0.00221\ttrain-auc:0.97905+0.00048\ttest-logloss:0.37295+0.00425\ttest-auc:0.91998+0.00180\n",
      "[3250]\ttrain-logloss:0.23979+0.00220\ttrain-auc:0.97938+0.00048\ttest-logloss:0.37286+0.00431\ttest-auc:0.91999+0.00178\n",
      "[3300]\ttrain-logloss:0.23853+0.00223\ttrain-auc:0.97969+0.00049\ttest-logloss:0.37290+0.00434\ttest-auc:0.91999+0.00178\n",
      "[3307]\ttrain-logloss:0.23834+0.00217\ttrain-auc:0.97973+0.00049\ttest-logloss:0.37289+0.00438\ttest-auc:0.91999+0.00177\n"
     ]
    }
   ],
   "source": [
    "genes_dmatrix = xgb.DMatrix(data=X, label =y)\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.1, # Corresponds to learning_rate\n",
    "    'max_depth': 5,\n",
    "    'min_child_weight': 1,\n",
    "    'gamma': 0,\n",
    "    'subsample': 0.8,\n",
    "    'colsample_bytree': 0.8,\n",
    "    'scale_pos_weight': 3,\n",
    "    'seed': 27, # Seed for internal XGBoost randomness (like feature subsampling)\n",
    "    'nthread': -1\n",
    "}\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params = params,\n",
    "    dtrain = genes_dmatrix,\n",
    "    num_boost_round = 4000,\n",
    "    nfold = 5,\n",
    "    metrics = {'logloss', 'auc'},\n",
    "    early_stopping_rounds = 50,\n",
    "    seed = 27,\n",
    "    verbose_eval = 50\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.680279</td>\n",
       "      <td>0.002629</td>\n",
       "      <td>0.623371</td>\n",
       "      <td>0.007216</td>\n",
       "      <td>0.690569</td>\n",
       "      <td>0.002600</td>\n",
       "      <td>0.506240</td>\n",
       "      <td>0.009338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.679318</td>\n",
       "      <td>0.002594</td>\n",
       "      <td>0.630752</td>\n",
       "      <td>0.008529</td>\n",
       "      <td>0.690579</td>\n",
       "      <td>0.002524</td>\n",
       "      <td>0.508000</td>\n",
       "      <td>0.008719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.678173</td>\n",
       "      <td>0.002669</td>\n",
       "      <td>0.634738</td>\n",
       "      <td>0.008981</td>\n",
       "      <td>0.689942</td>\n",
       "      <td>0.002353</td>\n",
       "      <td>0.510875</td>\n",
       "      <td>0.009142</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.677020</td>\n",
       "      <td>0.002146</td>\n",
       "      <td>0.637230</td>\n",
       "      <td>0.008550</td>\n",
       "      <td>0.689755</td>\n",
       "      <td>0.002516</td>\n",
       "      <td>0.511950</td>\n",
       "      <td>0.008992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.675554</td>\n",
       "      <td>0.002405</td>\n",
       "      <td>0.642632</td>\n",
       "      <td>0.009216</td>\n",
       "      <td>0.689426</td>\n",
       "      <td>0.002295</td>\n",
       "      <td>0.513750</td>\n",
       "      <td>0.010016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-logloss-mean  train-logloss-std  train-auc-mean  train-auc-std  \\\n",
       "7             0.680279           0.002629        0.623371       0.007216   \n",
       "8             0.679318           0.002594        0.630752       0.008529   \n",
       "9             0.678173           0.002669        0.634738       0.008981   \n",
       "10            0.677020           0.002146        0.637230       0.008550   \n",
       "11            0.675554           0.002405        0.642632       0.009216   \n",
       "\n",
       "    test-logloss-mean  test-logloss-std  test-auc-mean  test-auc-std  \n",
       "7            0.690569          0.002600       0.506240      0.009338  \n",
       "8            0.690579          0.002524       0.508000      0.008719  \n",
       "9            0.689942          0.002353       0.510875      0.009142  \n",
       "10           0.689755          0.002516       0.511950      0.008992  \n",
       "11           0.689426          0.002295       0.513750      0.010016  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv_results\n",
    "cv_results.tail()\n",
    "# optimal_rounds = cv_results.shape[0]\n",
    "# print(optimal_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-4 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-4 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-4 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-4 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-4 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-4 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-4 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-4 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-4 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=120,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=120,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.8, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=5,\n",
       "              max_leaves=None, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=120,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#base model\n",
    "xgb1_1 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=120,\n",
    " max_depth=5,\n",
    " min_child_weight=1,\n",
    " gamma=0,\n",
    " subsample=0.8,\n",
    " colsample_bytree=0.8,\n",
    " objective= 'binary:logistic',\n",
    " n_jobs=-1,\n",
    " scale_pos_weight=scale_pos_weight_val,\n",
    " seed=27)\n",
    "\n",
    "xgb1_1.fit(X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[102 142]\n",
      " [370 357]]\n",
      "Accuracy: 0.4727085478887745\n",
      "Precision: 0.7154308617234469\n",
      "Recall: 0.49105914718019256\n",
      "F1 Score: 0.5823817292006526\n",
      "Final Model ROC AUC: 0.4722\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.42      0.28       244\n",
      "           1       0.72      0.49      0.58       727\n",
      "\n",
      "    accuracy                           0.47       971\n",
      "   macro avg       0.47      0.45      0.43       971\n",
      "weighted avg       0.59      0.47      0.51       971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred_proba = xgb1_1.predict_proba(X_test_filtered)[:,1]\n",
    "y_pred = xgb1_1.predict(X_test_filtered)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "print(f\"Final Model ROC AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step2: Tune max_depth and min_child_weigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        2.970508      0.425429         0.396609        0.026358   \n",
      "1        2.834768      0.456463         0.405674        0.006758   \n",
      "2        3.068122      0.192124         0.368063        0.044089   \n",
      "3        2.747983      0.487982         0.389913        0.033693   \n",
      "4        2.421840      0.265088         0.415112        0.081698   \n",
      "5        3.001717      0.459126         0.397114        0.011725   \n",
      "6        2.873758      0.426151         0.396362        0.016078   \n",
      "7        2.664079      0.475909         0.398980        0.008429   \n",
      "8        2.078604      0.128365         0.396349        0.008481   \n",
      "9        2.305181      0.555536         0.438159        0.085946   \n",
      "10       2.229320      0.502983         0.397833        0.008538   \n",
      "11       2.069347      0.133278         0.395726        0.005745   \n",
      "\n",
      "    param_max_depth  param_min_child_weight  \\\n",
      "0                 4                       6   \n",
      "1                 4                       8   \n",
      "2                 4                      10   \n",
      "3                 4                      12   \n",
      "4                 5                       6   \n",
      "5                 5                       8   \n",
      "6                 5                      10   \n",
      "7                 5                      12   \n",
      "8                 6                       6   \n",
      "9                 6                       8   \n",
      "10                6                      10   \n",
      "11                6                      12   \n",
      "\n",
      "                                      params  split0_test_score  \\\n",
      "0    {'max_depth': 4, 'min_child_weight': 6}           0.532212   \n",
      "1    {'max_depth': 4, 'min_child_weight': 8}           0.530818   \n",
      "2   {'max_depth': 4, 'min_child_weight': 10}           0.502414   \n",
      "3   {'max_depth': 4, 'min_child_weight': 12}           0.524780   \n",
      "4    {'max_depth': 5, 'min_child_weight': 6}           0.536634   \n",
      "5    {'max_depth': 5, 'min_child_weight': 8}           0.521135   \n",
      "6   {'max_depth': 5, 'min_child_weight': 10}           0.502608   \n",
      "7   {'max_depth': 5, 'min_child_weight': 12}           0.524961   \n",
      "8    {'max_depth': 6, 'min_child_weight': 6}           0.524489   \n",
      "9    {'max_depth': 6, 'min_child_weight': 8}           0.522958   \n",
      "10  {'max_depth': 6, 'min_child_weight': 10}           0.503027   \n",
      "11  {'max_depth': 6, 'min_child_weight': 12}           0.525239   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.535800           0.532512           0.548407   \n",
      "1            0.535505           0.543925           0.523156   \n",
      "2            0.539477           0.558785           0.516939   \n",
      "3            0.526471           0.562077           0.509437   \n",
      "4            0.524661           0.547685           0.545422   \n",
      "5            0.533042           0.539450           0.523364   \n",
      "6            0.539357           0.558590           0.519724   \n",
      "7            0.522181           0.561508           0.513329   \n",
      "8            0.539830           0.546758           0.545302   \n",
      "9            0.527455           0.553520           0.521389   \n",
      "10           0.532181           0.561335           0.519680   \n",
      "11           0.521704           0.561658           0.513374   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.525676         0.534922        0.007500                3  \n",
      "1            0.520822         0.530845        0.008395                5  \n",
      "2            0.514166         0.526356        0.020171               10  \n",
      "3            0.507905         0.526134        0.019519               12  \n",
      "4            0.528010         0.536482        0.009132                2  \n",
      "5            0.518732         0.527145        0.007841                7  \n",
      "6            0.518201         0.527696        0.019357                6  \n",
      "7            0.511168         0.526630        0.018193                9  \n",
      "8            0.537128         0.538701        0.007928                1  \n",
      "9            0.532230         0.531510        0.011636                4  \n",
      "10           0.515163         0.526277        0.019857               11  \n",
      "11           0.511248         0.526645        0.018251                8  \n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "8        2.078604      0.128365         0.396349        0.008481   \n",
      "4        2.421840      0.265088         0.415112        0.081698   \n",
      "0        2.970508      0.425429         0.396609        0.026358   \n",
      "9        2.305181      0.555536         0.438159        0.085946   \n",
      "1        2.834768      0.456463         0.405674        0.006758   \n",
      "6        2.873758      0.426151         0.396362        0.016078   \n",
      "5        3.001717      0.459126         0.397114        0.011725   \n",
      "11       2.069347      0.133278         0.395726        0.005745   \n",
      "7        2.664079      0.475909         0.398980        0.008429   \n",
      "2        3.068122      0.192124         0.368063        0.044089   \n",
      "10       2.229320      0.502983         0.397833        0.008538   \n",
      "3        2.747983      0.487982         0.389913        0.033693   \n",
      "\n",
      "    param_max_depth  param_min_child_weight  \\\n",
      "8                 6                       6   \n",
      "4                 5                       6   \n",
      "0                 4                       6   \n",
      "9                 6                       8   \n",
      "1                 4                       8   \n",
      "6                 5                      10   \n",
      "5                 5                       8   \n",
      "11                6                      12   \n",
      "7                 5                      12   \n",
      "2                 4                      10   \n",
      "10                6                      10   \n",
      "3                 4                      12   \n",
      "\n",
      "                                      params  split0_test_score  \\\n",
      "8    {'max_depth': 6, 'min_child_weight': 6}           0.524489   \n",
      "4    {'max_depth': 5, 'min_child_weight': 6}           0.536634   \n",
      "0    {'max_depth': 4, 'min_child_weight': 6}           0.532212   \n",
      "9    {'max_depth': 6, 'min_child_weight': 8}           0.522958   \n",
      "1    {'max_depth': 4, 'min_child_weight': 8}           0.530818   \n",
      "6   {'max_depth': 5, 'min_child_weight': 10}           0.502608   \n",
      "5    {'max_depth': 5, 'min_child_weight': 8}           0.521135   \n",
      "11  {'max_depth': 6, 'min_child_weight': 12}           0.525239   \n",
      "7   {'max_depth': 5, 'min_child_weight': 12}           0.524961   \n",
      "2   {'max_depth': 4, 'min_child_weight': 10}           0.502414   \n",
      "10  {'max_depth': 6, 'min_child_weight': 10}           0.503027   \n",
      "3   {'max_depth': 4, 'min_child_weight': 12}           0.524780   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "8            0.539830           0.546758           0.545302   \n",
      "4            0.524661           0.547685           0.545422   \n",
      "0            0.535800           0.532512           0.548407   \n",
      "9            0.527455           0.553520           0.521389   \n",
      "1            0.535505           0.543925           0.523156   \n",
      "6            0.539357           0.558590           0.519724   \n",
      "5            0.533042           0.539450           0.523364   \n",
      "11           0.521704           0.561658           0.513374   \n",
      "7            0.522181           0.561508           0.513329   \n",
      "2            0.539477           0.558785           0.516939   \n",
      "10           0.532181           0.561335           0.519680   \n",
      "3            0.526471           0.562077           0.509437   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "8            0.537128         0.538701        0.007928                1  \n",
      "4            0.528010         0.536482        0.009132                2  \n",
      "0            0.525676         0.534922        0.007500                3  \n",
      "9            0.532230         0.531510        0.011636                4  \n",
      "1            0.520822         0.530845        0.008395                5  \n",
      "6            0.518201         0.527696        0.019357                6  \n",
      "5            0.518732         0.527145        0.007841                7  \n",
      "11           0.511248         0.526645        0.018251                8  \n",
      "7            0.511168         0.526630        0.018193                9  \n",
      "2            0.514166         0.526356        0.020171               10  \n",
      "10           0.515163         0.526277        0.019857               11  \n",
      "3            0.507905         0.526134        0.019519               12  \n",
      "best_params:{'max_depth': 6, 'min_child_weight': 6}\n",
      "Best_score:0.5387014438199857\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "#  'max_depth':range(3,10,2),\n",
    "#  'min_child_weight':range(1,6,2)\n",
    "\n",
    " 'max_depth':[4,5,6],#6\n",
    " 'min_child_weight':[6,8,10,12] #6\n",
    "}\n",
    "xgb_2_1=xgb.XGBClassifier( learning_rate =0.1, \n",
    "                        n_estimators=12, \n",
    "                        max_depth=5,\n",
    "                        min_child_weight=1, \n",
    "                        gamma=0, \n",
    "                        subsample=0.8, \n",
    "                        colsample_bytree=0.8,\n",
    "                        objective= 'binary:logistic', \n",
    "                        nthread=4, \n",
    "                        scale_pos_weight=scale_pos_weight_val, \n",
    "                        seed=27)\n",
    "gsearch1 = GridSearchCV(estimator = xgb_2_1, \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=-1, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch1.fit(X_train_filtered,y_train)\n",
    "\n",
    "results_df = pd.DataFrame(gsearch1.cv_results_)\n",
    "print(results_df)\n",
    "print(results_df.sort_values(by='rank_test_score'))\n",
    "\n",
    "print(f\"best_params:{gsearch1.best_params_}\") \n",
    "print(f\"Best_score:{gsearch1.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step3: tune gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n",
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/xgboost/core.py:377: FutureWarning: Your system has an old version of glibc (< 2.28). We will stop supporting Linux distros with glibc older than 2.28 after **May 31, 2025**. Please upgrade to a recent Linux distro (with glibc >= 2.28) to use future versions of XGBoost.\n",
      "Note: You have installed the 'manylinux2014' variant of XGBoost. Certain features such as GPU algorithms or federated learning are not available. To use these features, please upgrade to a recent Linux distro with glibc 2.28+, and install the 'manylinux_2_28' variant.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_gamma  \\\n",
      "0       2.032600      0.024619         0.403394        0.008197          0.0   \n",
      "1       2.050518      0.020248         0.395679        0.009032          0.1   \n",
      "2       1.976160      0.143037         0.375062        0.046722          0.2   \n",
      "3       2.053400      0.007613         0.401876        0.005214          0.3   \n",
      "4       2.071623      0.032929         0.411520        0.011318          0.4   \n",
      "\n",
      "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
      "0  {'gamma': 0.0}           0.524489            0.53983           0.546758   \n",
      "1  {'gamma': 0.1}           0.524489            0.53983           0.545699   \n",
      "2  {'gamma': 0.2}           0.524489            0.53983           0.545699   \n",
      "3  {'gamma': 0.3}           0.524489            0.53983           0.545699   \n",
      "4  {'gamma': 0.4}           0.524489            0.53983           0.545699   \n",
      "\n",
      "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
      "0           0.545302           0.537128         0.538701        0.007928   \n",
      "1           0.545302           0.537128         0.538490        0.007721   \n",
      "2           0.546409           0.537128         0.538711        0.007926   \n",
      "3           0.546409           0.537128         0.538711        0.007926   \n",
      "4           0.546409           0.537128         0.538711        0.007926   \n",
      "\n",
      "   rank_test_score  \n",
      "0                4  \n",
      "1                5  \n",
      "2                1  \n",
      "3                1  \n",
      "4                1  \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  param_gamma  \\\n",
      "3       2.053400      0.007613         0.401876        0.005214          0.3   \n",
      "2       1.976160      0.143037         0.375062        0.046722          0.2   \n",
      "4       2.071623      0.032929         0.411520        0.011318          0.4   \n",
      "0       2.032600      0.024619         0.403394        0.008197          0.0   \n",
      "1       2.050518      0.020248         0.395679        0.009032          0.1   \n",
      "\n",
      "           params  split0_test_score  split1_test_score  split2_test_score  \\\n",
      "3  {'gamma': 0.3}           0.524489            0.53983           0.545699   \n",
      "2  {'gamma': 0.2}           0.524489            0.53983           0.545699   \n",
      "4  {'gamma': 0.4}           0.524489            0.53983           0.545699   \n",
      "0  {'gamma': 0.0}           0.524489            0.53983           0.546758   \n",
      "1  {'gamma': 0.1}           0.524489            0.53983           0.545699   \n",
      "\n",
      "   split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
      "3           0.546409           0.537128         0.538711        0.007926   \n",
      "2           0.546409           0.537128         0.538711        0.007926   \n",
      "4           0.546409           0.537128         0.538711        0.007926   \n",
      "0           0.545302           0.537128         0.538701        0.007928   \n",
      "1           0.545302           0.537128         0.538490        0.007721   \n",
      "\n",
      "   rank_test_score  \n",
      "3                1  \n",
      "2                1  \n",
      "4                1  \n",
      "0                4  \n",
      "1                5  \n",
      "best_params:{'gamma': 0.2}\n",
      "Best_score:0.5387110266721302\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "'gamma':[i/10.0 for i in range(0,5)] #0.2\n",
    "}\n",
    "xgb_2_1=xgb.XGBClassifier( learning_rate =0.1, \n",
    "                        n_estimators=12, \n",
    "                        max_depth=6,\n",
    "                        min_child_weight=6, \n",
    "                        gamma=0, \n",
    "                        subsample=0.8, \n",
    "                        colsample_bytree=0.8,\n",
    "                        objective= 'binary:logistic', \n",
    "                        nthread=4, \n",
    "                        scale_pos_weight=scale_pos_weight_val, \n",
    "                        seed=27)\n",
    "gsearch1 = GridSearchCV(estimator = xgb_2_1, \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=-1, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch1.fit(X_train_filtered,y_train)\n",
    "\n",
    "results_df = pd.DataFrame(gsearch1.cv_results_)\n",
    "print(results_df)\n",
    "print(results_df.sort_values(by='rank_test_score'))\n",
    "\n",
    "print(f\"best_params:{gsearch1.best_params_}\") \n",
    "print(f\"Best_score:{gsearch1.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Tune subsample and colsample_bytree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0        4.731436      1.491592         0.547544        0.019983   \n",
      "1        4.848363      2.028891         0.651835        0.094777   \n",
      "2        5.476722      1.724943         0.590022        0.022809   \n",
      "3        6.360034      1.636496         0.590580        0.048307   \n",
      "4        6.288605      1.445792         0.642595        0.028535   \n",
      "..            ...           ...              ...             ...   \n",
      "76       2.368969      0.163884         0.275377        0.016652   \n",
      "77       2.249490      0.131008         0.299529        0.020305   \n",
      "78       2.252794      0.090927         0.279917        0.017869   \n",
      "79       2.099086      0.229107         0.296693        0.009932   \n",
      "80       2.072867      0.108699         0.270310        0.007329   \n",
      "\n",
      "    param_colsample_bytree  param_subsample  \\\n",
      "0                      0.1              0.1   \n",
      "1                      0.1              0.2   \n",
      "2                      0.1              0.3   \n",
      "3                      0.1              0.4   \n",
      "4                      0.1              0.5   \n",
      "..                     ...              ...   \n",
      "76                     0.9              0.5   \n",
      "77                     0.9              0.6   \n",
      "78                     0.9              0.7   \n",
      "79                     0.9              0.8   \n",
      "80                     0.9              0.9   \n",
      "\n",
      "                                         params  split0_test_score  \\\n",
      "0   {'colsample_bytree': 0.1, 'subsample': 0.1}           0.500000   \n",
      "1   {'colsample_bytree': 0.1, 'subsample': 0.2}           0.478282   \n",
      "2   {'colsample_bytree': 0.1, 'subsample': 0.3}           0.526894   \n",
      "3   {'colsample_bytree': 0.1, 'subsample': 0.4}           0.516872   \n",
      "4   {'colsample_bytree': 0.1, 'subsample': 0.5}           0.523840   \n",
      "..                                          ...                ...   \n",
      "76  {'colsample_bytree': 0.9, 'subsample': 0.5}           0.527856   \n",
      "77  {'colsample_bytree': 0.9, 'subsample': 0.6}           0.516492   \n",
      "78  {'colsample_bytree': 0.9, 'subsample': 0.7}           0.515954   \n",
      "79  {'colsample_bytree': 0.9, 'subsample': 0.8}           0.525773   \n",
      "80  {'colsample_bytree': 0.9, 'subsample': 0.9}           0.531444   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "0            0.500000           0.500000           0.500000   \n",
      "1            0.524547           0.530001           0.467354   \n",
      "2            0.522459           0.543546           0.480019   \n",
      "3            0.543334           0.542544           0.489345   \n",
      "4            0.522208           0.549865           0.500558   \n",
      "..                ...                ...                ...   \n",
      "76           0.541004           0.545686           0.514680   \n",
      "77           0.515813           0.532389           0.528173   \n",
      "78           0.517710           0.543131           0.525206   \n",
      "79           0.516563           0.539887           0.533948   \n",
      "80           0.535986           0.552125           0.537743   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "0            0.500000         0.500000        0.000000               73  \n",
      "1            0.503676         0.500772        0.024700               72  \n",
      "2            0.528771         0.520338        0.021367               63  \n",
      "3            0.526353         0.523690        0.019872               54  \n",
      "4            0.543248         0.527944        0.017404               36  \n",
      "..                ...              ...             ...              ...  \n",
      "76           0.515632         0.528972        0.012709               32  \n",
      "77           0.539235         0.526421        0.009100               47  \n",
      "78           0.524790         0.525358        0.009624               50  \n",
      "79           0.529546         0.529144        0.007852               29  \n",
      "80           0.524290         0.536318        0.009170               12  \n",
      "\n",
      "[81 rows x 15 columns]\n",
      "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "15       5.519583      1.178734         0.624033        0.065896   \n",
      "34       3.778307      0.269934         0.630670        0.049751   \n",
      "6        5.611713      1.715039         0.625388        0.074826   \n",
      "25       6.768967      0.225759         0.579656        0.040050   \n",
      "7        4.000343      1.381822         0.603002        0.020589   \n",
      "..            ...           ...              ...             ...   \n",
      "9        4.104300      1.048253         0.571423        0.037456   \n",
      "0        4.731436      1.491592         0.547544        0.019983   \n",
      "18       6.348743      0.106812         0.612823        0.044894   \n",
      "27       6.906684      0.197015         0.592055        0.032643   \n",
      "72       2.425388      0.141135         0.326919        0.023493   \n",
      "\n",
      "    param_colsample_bytree  param_subsample  \\\n",
      "15                     0.2              0.7   \n",
      "34                     0.4              0.8   \n",
      "6                      0.1              0.7   \n",
      "25                     0.3              0.8   \n",
      "7                      0.1              0.8   \n",
      "..                     ...              ...   \n",
      "9                      0.2              0.1   \n",
      "0                      0.1              0.1   \n",
      "18                     0.3              0.1   \n",
      "27                     0.4              0.1   \n",
      "72                     0.9              0.1   \n",
      "\n",
      "                                         params  split0_test_score  \\\n",
      "15  {'colsample_bytree': 0.2, 'subsample': 0.7}           0.532521   \n",
      "34  {'colsample_bytree': 0.4, 'subsample': 0.8}           0.532945   \n",
      "6   {'colsample_bytree': 0.1, 'subsample': 0.7}           0.541480   \n",
      "25  {'colsample_bytree': 0.3, 'subsample': 0.8}           0.529622   \n",
      "7   {'colsample_bytree': 0.1, 'subsample': 0.8}           0.533444   \n",
      "..                                          ...                ...   \n",
      "9   {'colsample_bytree': 0.2, 'subsample': 0.1}           0.500000   \n",
      "0   {'colsample_bytree': 0.1, 'subsample': 0.1}           0.500000   \n",
      "18  {'colsample_bytree': 0.3, 'subsample': 0.1}           0.500000   \n",
      "27  {'colsample_bytree': 0.4, 'subsample': 0.1}           0.500000   \n",
      "72  {'colsample_bytree': 0.9, 'subsample': 0.1}           0.500000   \n",
      "\n",
      "    split1_test_score  split2_test_score  split3_test_score  \\\n",
      "15           0.543890           0.578371           0.528900   \n",
      "34           0.546194           0.560696           0.532832   \n",
      "6            0.526303           0.550854           0.536131   \n",
      "25           0.543148           0.562849           0.538146   \n",
      "7            0.532301           0.554062           0.529174   \n",
      "..                ...                ...                ...   \n",
      "9            0.500000           0.500000           0.500000   \n",
      "0            0.500000           0.500000           0.500000   \n",
      "18           0.500000           0.500000           0.500000   \n",
      "27           0.500000           0.500000           0.500000   \n",
      "72           0.500000           0.500000           0.500000   \n",
      "\n",
      "    split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
      "15           0.537088         0.544154        0.017826                1  \n",
      "34           0.536428         0.541819        0.010621                2  \n",
      "6            0.552831         0.541520        0.009753                3  \n",
      "25           0.527655         0.540284        0.012611                4  \n",
      "7            0.551768         0.540150        0.010541                5  \n",
      "..                ...              ...             ...              ...  \n",
      "9            0.500000         0.500000        0.000000               73  \n",
      "0            0.500000         0.500000        0.000000               73  \n",
      "18           0.500000         0.500000        0.000000               73  \n",
      "27           0.500000         0.500000        0.000000               73  \n",
      "72           0.500000         0.500000        0.000000               73  \n",
      "\n",
      "[81 rows x 15 columns]\n",
      "best_params:{'colsample_bytree': 0.2, 'subsample': 0.7}\n",
      "Best_score:0.5441538233910251\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "'subsample':[i/10.0 for i in range(1,10)], #0.2\n",
    " 'colsample_bytree':[i/10.0 for i in range(1,10)] #0.7\n",
    "}\n",
    "xgb_2_1=xgb.XGBClassifier( learning_rate =0.1, \n",
    "                        n_estimators=12, \n",
    "                        max_depth=6,\n",
    "                        min_child_weight=6, \n",
    "                        gamma=0.2, \n",
    "                        subsample=0.8, \n",
    "                        colsample_bytree=0.8,\n",
    "                        objective= 'binary:logistic', \n",
    "                        nthread=4, \n",
    "                        scale_pos_weight=scale_pos_weight_val, \n",
    "                        seed=27)\n",
    "gsearch1 = GridSearchCV(estimator = xgb_2_1, \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=-1, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch1.fit(X_train_filtered,y_train)\n",
    "\n",
    "results_df = pd.DataFrame(gsearch1.cv_results_)\n",
    "print(results_df)\n",
    "print(results_df.sort_values(by='rank_test_score'))\n",
    "\n",
    "print(f\"best_params:{gsearch1.best_params_}\") \n",
    "print(f\"Best_score:{gsearch1.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Tuning Regularization Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/hdd1/home/f24_yqzhou/miniconda3/envs/6010/lib/python3.13/site-packages/joblib/externals/loky/process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "0       1.781503      0.094548         0.363194        0.016390   \n",
      "1       1.764673      0.093487         0.356649        0.042511   \n",
      "2       1.735071      0.063197         0.429946        0.012459   \n",
      "3       1.713412      0.077029         0.390649        0.025509   \n",
      "4       1.725825      0.051106         0.362806        0.063024   \n",
      "\n",
      "   param_reg_alpha                params  split0_test_score  \\\n",
      "0            0.000      {'reg_alpha': 0}           0.532521   \n",
      "1            0.001  {'reg_alpha': 0.001}           0.532592   \n",
      "2            0.005  {'reg_alpha': 0.005}           0.532601   \n",
      "3            0.010   {'reg_alpha': 0.01}           0.532610   \n",
      "4            0.050   {'reg_alpha': 0.05}           0.531665   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "0           0.543890           0.578371           0.528900           0.537088   \n",
      "1           0.543899           0.578371           0.528900           0.537088   \n",
      "2           0.543837           0.578371           0.528917           0.537088   \n",
      "3           0.543846           0.575202           0.528917           0.537088   \n",
      "4           0.543881           0.571729           0.528997           0.535325   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "0         0.544154        0.017826                3  \n",
      "1         0.544170        0.017817                1  \n",
      "2         0.544163        0.017813                2  \n",
      "3         0.543532        0.016598                4  \n",
      "4         0.542319        0.015539                5  \n",
      "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
      "1       1.764673      0.093487         0.356649        0.042511   \n",
      "2       1.735071      0.063197         0.429946        0.012459   \n",
      "0       1.781503      0.094548         0.363194        0.016390   \n",
      "3       1.713412      0.077029         0.390649        0.025509   \n",
      "4       1.725825      0.051106         0.362806        0.063024   \n",
      "\n",
      "   param_reg_alpha                params  split0_test_score  \\\n",
      "1            0.001  {'reg_alpha': 0.001}           0.532592   \n",
      "2            0.005  {'reg_alpha': 0.005}           0.532601   \n",
      "0            0.000      {'reg_alpha': 0}           0.532521   \n",
      "3            0.010   {'reg_alpha': 0.01}           0.532610   \n",
      "4            0.050   {'reg_alpha': 0.05}           0.531665   \n",
      "\n",
      "   split1_test_score  split2_test_score  split3_test_score  split4_test_score  \\\n",
      "1           0.543899           0.578371           0.528900           0.537088   \n",
      "2           0.543837           0.578371           0.528917           0.537088   \n",
      "0           0.543890           0.578371           0.528900           0.537088   \n",
      "3           0.543846           0.575202           0.528917           0.537088   \n",
      "4           0.543881           0.571729           0.528997           0.535325   \n",
      "\n",
      "   mean_test_score  std_test_score  rank_test_score  \n",
      "1         0.544170        0.017817                1  \n",
      "2         0.544163        0.017813                2  \n",
      "0         0.544154        0.017826                3  \n",
      "3         0.543532        0.016598                4  \n",
      "4         0.542319        0.015539                5  \n",
      "best_params:{'reg_alpha': 0.001}\n",
      "Best_score:0.5441697111177562\n"
     ]
    }
   ],
   "source": [
    "param_test1 = {\n",
    "'reg_alpha':[0, 0.001, 0.005, 0.01, 0.05] #0.001\n",
    "}\n",
    "xgb_2_1=xgb.XGBClassifier( learning_rate =0.1, \n",
    "                        n_estimators=12, \n",
    "                        max_depth=6,\n",
    "                        min_child_weight=6, \n",
    "                        gamma=0.2, \n",
    "                        subsample=0.7, \n",
    "                        colsample_bytree=0.2,\n",
    "                        objective= 'binary:logistic', \n",
    "                        nthread=4, \n",
    "                        scale_pos_weight=scale_pos_weight_val, \n",
    "                        seed=27)\n",
    "gsearch1 = GridSearchCV(estimator = xgb_2_1, \n",
    "                        param_grid = param_test1, \n",
    "                        scoring='roc_auc',\n",
    "                        n_jobs=-1, \n",
    "                        cv=5)\n",
    "\n",
    "gsearch1.fit(X_train_filtered,y_train)\n",
    "\n",
    "results_df = pd.DataFrame(gsearch1.cv_results_)\n",
    "print(results_df)\n",
    "print(results_df.sort_values(by='rank_test_score'))\n",
    "\n",
    "print(f\"best_params:{gsearch1.best_params_}\") \n",
    "print(f\"Best_score:{gsearch1.best_score_}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### retune estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.69291+0.00309\ttrain-auc:0.53152+0.00246\ttest-logloss:0.69356+0.00294\ttest-auc:0.51079+0.01433\n",
      "[5]\ttrain-logloss:0.68966+0.00328\ttrain-auc:0.56154+0.00330\ttest-logloss:0.69170+0.00374\ttest-auc:0.52728+0.01091\n",
      "[10]\ttrain-logloss:0.68778+0.00338\ttrain-auc:0.57083+0.00462\ttest-logloss:0.69126+0.00363\ttest-auc:0.52641+0.00754\n",
      "[15]\ttrain-logloss:0.68605+0.00365\ttrain-auc:0.57148+0.00303\ttest-logloss:0.69082+0.00352\ttest-auc:0.52526+0.00620\n",
      "[20]\ttrain-logloss:0.68459+0.00364\ttrain-auc:0.57692+0.00187\ttest-logloss:0.69042+0.00332\ttest-auc:0.52360+0.00770\n",
      "[25]\ttrain-logloss:0.68250+0.00235\ttrain-auc:0.58267+0.00263\ttest-logloss:0.68929+0.00317\ttest-auc:0.52877+0.00913\n",
      "[30]\ttrain-logloss:0.68259+0.00228\ttrain-auc:0.58376+0.00296\ttest-logloss:0.69049+0.00295\ttest-auc:0.52799+0.00831\n",
      "[35]\ttrain-logloss:0.68265+0.00249\ttrain-auc:0.58380+0.00308\ttest-logloss:0.69141+0.00350\ttest-auc:0.52632+0.00950\n",
      "[40]\ttrain-logloss:0.68131+0.00297\ttrain-auc:0.58732+0.00240\ttest-logloss:0.69119+0.00299\ttest-auc:0.52614+0.01081\n",
      "[45]\ttrain-logloss:0.68053+0.00317\ttrain-auc:0.58909+0.00299\ttest-logloss:0.69086+0.00339\ttest-auc:0.52637+0.00966\n",
      "[50]\ttrain-logloss:0.67925+0.00372\ttrain-auc:0.58977+0.00188\ttest-logloss:0.69041+0.00485\ttest-auc:0.52408+0.01317\n",
      "[55]\ttrain-logloss:0.67861+0.00349\ttrain-auc:0.58986+0.00345\ttest-logloss:0.69007+0.00527\ttest-auc:0.52553+0.00975\n",
      "[60]\ttrain-logloss:0.67858+0.00320\ttrain-auc:0.59084+0.00316\ttest-logloss:0.69051+0.00566\ttest-auc:0.52706+0.00763\n",
      "[65]\ttrain-logloss:0.67728+0.00363\ttrain-auc:0.59282+0.00380\ttest-logloss:0.68993+0.00472\ttest-auc:0.52318+0.00727\n",
      "[70]\ttrain-logloss:0.67593+0.00510\ttrain-auc:0.59511+0.00423\ttest-logloss:0.68913+0.00399\ttest-auc:0.52487+0.00276\n",
      "[72]\ttrain-logloss:0.67634+0.00537\ttrain-auc:0.59466+0.00428\ttest-logloss:0.68947+0.00339\ttest-auc:0.52627+0.00428\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "genes_dmatrix = xgb.DMatrix(data=X_train_filtered, label =y_train)\n",
    "params = {\n",
    "    'objective': 'binary:logistic',\n",
    "    'eta': 0.1, # Corresponds to learning_rate\n",
    "    'max_depth': 6,\n",
    "    'min_child_weight': 6,\n",
    "    'gamma': 0.2,\n",
    "    'subsample': 0.7,\n",
    "    'colsample_bytree': 0.2,\n",
    "    'scale_pos_weight': scale_pos_weight_val,\n",
    "    'seed': 27, # Seed for internal XGBoost randomness (like feature subsampling)\n",
    "    'nthread': -1,\n",
    "    'reg_alpha': 0.001\n",
    "}\n",
    "\n",
    "cv_results = xgb.cv(\n",
    "    params = params,\n",
    "    dtrain = genes_dmatrix,\n",
    "    num_boost_round = 4000,\n",
    "    nfold = 5,\n",
    "    metrics = {'logloss', 'auc'},\n",
    "    early_stopping_rounds = 50,\n",
    "    seed = 27,\n",
    "    verbose_eval = 5\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-logloss-mean</th>\n",
       "      <th>train-logloss-std</th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-logloss-mean</th>\n",
       "      <th>test-logloss-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.684830</td>\n",
       "      <td>0.003404</td>\n",
       "      <td>0.576018</td>\n",
       "      <td>0.003134</td>\n",
       "      <td>0.690420</td>\n",
       "      <td>0.002878</td>\n",
       "      <td>0.522379</td>\n",
       "      <td>0.005253</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.684591</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>0.576925</td>\n",
       "      <td>0.001873</td>\n",
       "      <td>0.690424</td>\n",
       "      <td>0.003317</td>\n",
       "      <td>0.523600</td>\n",
       "      <td>0.007698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.684440</td>\n",
       "      <td>0.002700</td>\n",
       "      <td>0.578172</td>\n",
       "      <td>0.002190</td>\n",
       "      <td>0.690416</td>\n",
       "      <td>0.002624</td>\n",
       "      <td>0.526965</td>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.684126</td>\n",
       "      <td>0.002500</td>\n",
       "      <td>0.579772</td>\n",
       "      <td>0.002357</td>\n",
       "      <td>0.690231</td>\n",
       "      <td>0.002767</td>\n",
       "      <td>0.530925</td>\n",
       "      <td>0.008930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.683574</td>\n",
       "      <td>0.002519</td>\n",
       "      <td>0.580710</td>\n",
       "      <td>0.001798</td>\n",
       "      <td>0.689773</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.531280</td>\n",
       "      <td>0.009691</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    train-logloss-mean  train-logloss-std  train-auc-mean  train-auc-std  \\\n",
       "19            0.684830           0.003404        0.576018       0.003134   \n",
       "20            0.684591           0.003635        0.576925       0.001873   \n",
       "21            0.684440           0.002700        0.578172       0.002190   \n",
       "22            0.684126           0.002500        0.579772       0.002357   \n",
       "23            0.683574           0.002519        0.580710       0.001798   \n",
       "\n",
       "    test-logloss-mean  test-logloss-std  test-auc-mean  test-auc-std  \n",
       "19           0.690420          0.002878       0.522379      0.005253  \n",
       "20           0.690424          0.003317       0.523600      0.007698  \n",
       "21           0.690416          0.002624       0.526965      0.005657  \n",
       "22           0.690231          0.002767       0.530925      0.008930  \n",
       "23           0.689773          0.002944       0.531280      0.009691  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# cv_results\n",
    "cv_results.tail()\n",
    "# optimal_rounds = cv_results.shape[0]\n",
    "# print(optimal_rounds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24\n"
     ]
    }
   ],
   "source": [
    "optimal_rounds = cv_results.shape[0]\n",
    "print(optimal_rounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-5 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-5 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-5 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-5 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-5 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-5 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-5 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-5 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-5 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-5 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.2, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=6, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=24,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>XGBClassifier</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://xgboost.readthedocs.io/en/release_3.0.0/python/python_api.html#xgboost.XGBClassifier\">?<span>Documentation for XGBClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.2, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=6, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=24,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=0.2, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              feature_weights=None, gamma=0.2, grow_policy=None,\n",
       "              importance_type=None, interaction_constraints=None,\n",
       "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
       "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
       "              max_leaves=None, min_child_weight=6, missing=nan,\n",
       "              monotone_constraints=None, multi_strategy=None, n_estimators=24,\n",
       "              n_jobs=-1, num_parallel_tree=None, ...)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb3 = xgb.XGBClassifier(\n",
    " learning_rate =0.1,\n",
    " n_estimators=24,\n",
    " max_depth=6,\n",
    " min_child_weight=6,\n",
    " gamma=0.2,\n",
    " subsample=0.7,\n",
    " colsample_bytree=0.2,\n",
    " objective= 'binary:logistic',\n",
    " n_jobs=-1,\n",
    " scale_pos_weight=scale_pos_weight_val,\n",
    " seed=27,\n",
    " reg_alpha = 0.001\n",
    " )\n",
    "\n",
    "\n",
    "\n",
    "xgb3.fit(X_train_filtered, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[183  61]\n",
      " [516 211]]\n",
      "Accuracy: 0.4057672502574665\n",
      "Precision: 0.7757352941176471\n",
      "Recall: 0.2902338376891334\n",
      "F1 Score: 0.42242242242242245\n",
      "Final Model ROC AUC: 0.5242\n",
      "\n",
      "Final Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.26      0.75      0.39       244\n",
      "           1       0.78      0.29      0.42       727\n",
      "\n",
      "    accuracy                           0.41       971\n",
      "   macro avg       0.52      0.52      0.41       971\n",
      "weighted avg       0.65      0.41      0.41       971\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, classification_report\n",
    "\n",
    "y_pred_proba = xgb3.predict_proba(X_test_filtered)[:,1]\n",
    "y_pred = xgb3.predict(X_test_filtered)\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print(\"Confusion Matrix:\\n\", cm)\n",
    "# Accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "# Precision\n",
    "precision = precision_score(y_test, y_pred)\n",
    "print(\"Precision:\", precision)\n",
    "# Recall\n",
    "recall = recall_score(y_test, y_pred)\n",
    "print(\"Recall:\", recall)\n",
    "# F1 Score\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "print(\"F1 Score:\", f1)\n",
    "\n",
    "\n",
    "print(f\"Final Model ROC AUC: {roc_auc_score(y_test, y_pred_proba):.4f}\")\n",
    "print(\"\\nFinal Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "6010",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
